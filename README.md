# Vision-Based Autonomous Driving Agent

A comprehensive autonomous driving agent using Imitation Learning and Reinforcement Learning (PPO) in highway-env with domain randomization and multi-agent scenarios.

## ğŸ¯ Objectives

- âœ… Develop a robust autonomous driving agent capable of handling multiple real-world traffic scenarios
- âœ… Leverage Imitation Learning to bootstrap the model using expert driving behavior
- âœ… Apply Reinforcement Learning (PPO) to refine strategies in dynamic environments
- âœ… Utilize vision-based inputs for perception and decision-making
- âœ… Perform domain randomization to enhance generalization
- âœ… Integrate multi-agent traffic scenarios for real-world complexity

## ğŸš— Key Features

### Phase 1: Imitation Learning (CNN-based)
- Use highway-env's scripted expert or manual control
- Capture rendered frames and corresponding actions
- Train a Convolutional Neural Network to map visual input â†’ action output
- Learn basic behaviors like lane following, turning, and parking

### Phase 2: Reinforcement Learning (PPO)
- Initialize PPO agent with optional pretrained CNN weights from IL
- Use kinematic state vectors or rendered frames as input
- Apply custom reward shaping for optimal behavior
- Train across diverse traffic densities and road geometries

### Multi-Agent Simulation
- Spawn multiple agents with stochastic behavior
- Implement multi-agent complexity through different vehicle types
- Navigate realistic traffic and avoid collisions

## ğŸ›£ï¸ Supported Scenarios

- ğŸš˜ Lane following (highway-v0)
- ğŸš¦ Intersection handling (intersection-v0)
- ğŸ” Roundabout navigation (roundabout-v0)
- ğŸ…¿ï¸ Parking maneuvers (parking-v0)

## ğŸ§° Technologies & Tools

- **Simulator**: highway-env (2D lightweight driving simulator)
- **Language**: Python
- **Libraries**:
  - PyTorch (for CNN)
  - Stable-Baselines3 (PPO)
  - Imitation (for Behavioral Cloning)
  - OpenCV (image preprocessing)
  - Gymnasium for environment handling

## ğŸ“ Project Structure

```
â”œâ”€â”€ agents/                 # Agent implementations
â”‚   â”œâ”€â”€ cnn_agent.py       # CNN-based imitation learning agent
â”‚   â”œâ”€â”€ ppo_agent.py       # PPO reinforcement learning agent
â”‚   â””â”€â”€ hybrid_agent.py    # Combined IL+RL agent
â”œâ”€â”€ environments/           # Environment configurations and wrappers
â”‚   â”œâ”€â”€ env_configs.py     # Environment configurations
â”‚   â”œâ”€â”€ wrappers.py        # Custom environment wrappers
â”‚   â””â”€â”€ domain_randomization.py  # Domain randomization utilities
â”œâ”€â”€ models/                # Neural network architectures
â”‚   â”œâ”€â”€ cnn_models.py      # CNN architectures for vision
â”‚   â””â”€â”€ policy_networks.py # Policy networks for RL
â”œâ”€â”€ training/              # Training scripts and utilities
â”‚   â”œâ”€â”€ imitation_learning.py  # IL training pipeline
â”‚   â”œâ”€â”€ reinforcement_learning.py  # RL training pipeline
â”‚   â””â”€â”€ data_collection.py # Expert demonstration collection
â”œâ”€â”€ evaluation/            # Evaluation and testing
â”‚   â”œâ”€â”€ evaluate_agent.py  # Agent evaluation scripts
â”‚   â””â”€â”€ metrics.py         # Performance metrics
â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”œâ”€â”€ visualization.py   # Visualization tools
â”‚   â””â”€â”€ data_utils.py      # Data processing utilities
â”œâ”€â”€ configs/               # Configuration files
â”‚   â””â”€â”€ training_config.yaml  # Training hyperparameters
â”œâ”€â”€ scripts/               # Main execution scripts
â”‚   â”œâ”€â”€ train_il.py        # Train imitation learning agent
â”‚   â”œâ”€â”€ train_rl.py        # Train reinforcement learning agent
â”‚   â””â”€â”€ evaluate.py        # Evaluate trained agents
â”œâ”€â”€ simulation_viewer.py   # Full simulation viewer with trained agents
â”œâ”€â”€ quick_simulation.py    # Quick demonstrations without trained models
â”œâ”€â”€ test_simulation.py     # Test script for simulation capabilities
â””â”€â”€ SIMULATION_GUIDE.md    # Comprehensive simulation usage guide
```

## ğŸš€ Quick Start

1. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Train Imitation Learning Agent**:
   ```bash
   python scripts/train_il.py --env highway-v0 --episodes 1000
   ```

3. **Train Reinforcement Learning Agent**:
   ```bash
   python scripts/train_rl.py --env highway-v0 --pretrained_il path/to/il_model
   ```

4. **Evaluate Agent**:
   ```bash
   python scripts/evaluate.py --agent path/to/trained_agent --env highway-v0
   ```

## ğŸ“ˆ Expected Outcomes

A vision-based autonomous agent capable of:
- âœ… Navigating intersections, roundabouts, and parking
- âœ… Avoiding dynamic traffic agents
- âœ… Making real-time decisions under uncertainty
- âœ… Generalizing across varied conditions
- âœ… Achieving superior performance with IL+RL compared to IL-only

## ğŸ“¹ Simulation Viewing

### Quick Demonstrations (No Trained Models Required)

View simulations of all scenarios with simple rule-based agents:

```bash
# Test simulation capabilities
python test_simulation.py

# View a single scenario
python quick_simulation.py --scenario highway --render

# View all scenarios
python quick_simulation.py --scenario all --render --save_videos

# Interactive mode
python quick_simulation.py --interactive
```

### Full Simulation Viewer (With Trained Models)

View simulations with trained agents:

```bash
# View with trained RL agent
python simulation_viewer.py --scenario highway --agent_type rl --agent_path ./models/rl_model --render

# View all scenarios with hybrid agent
python simulation_viewer.py --scenario all --agent_type hybrid --agent_path ./models/hybrid_model --save_videos

# Interactive mode
python simulation_viewer.py --interactive --agent_type rl --agent_path ./models/rl_model
```

### Supported Scenarios

The agent will be evaluated on:
- ğŸ›£ï¸ **Highway Driving** - Multi-lane highway navigation with traffic
- ğŸš¦ **Intersection Handling** - Traffic light and stop sign navigation  
- ğŸ” **Roundabout Navigation** - Circular intersection navigation
- ğŸ…¿ï¸ **Parking Maneuvers** - Parallel and perpendicular parking

For detailed usage instructions, see [SIMULATION_GUIDE.md](SIMULATION_GUIDE.md).

## ğŸ”§ Configuration

Edit `configs/training_config.yaml` to customize:
- Training hyperparameters
- Environment settings
- Reward shaping
- Domain randomization parameters
- Multi-agent configurations

## ğŸ“Š Evaluation Metrics

- Episode reward
- Number of collisions
- Average time per episode
- Lane discipline consistency
- Success rate across different scenarios